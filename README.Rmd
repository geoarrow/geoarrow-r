---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
library(arrow)
library(sf)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# geoarrow

<!-- badges: start -->
[![R-CMD-check](https://github.com/paleolimbot/geoarrow/workflows/R-CMD-check/badge.svg)](https://github.com/paleolimbot/geoarrow/actions)
[![Codecov test coverage](https://codecov.io/gh/paleolimbot/geoarrow/branch/master/graph/badge.svg)](https://codecov.io/gh/paleolimbot/geoarrow?branch=master)
<!-- badges: end -->

The goal of geoarrow is to prototype Arrow representations of geometry. This is currently a [first-draft specification](https://github.com/jorisvandenbossche/geo-arrow-spec/blob/geo-arrow-format-initial/format.md) and nothing here should be used for anything except entertainment value. 

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("paleolimbot/geoarrow")
```

## Write a geoarrow parquet file

This exists for prototyping only, but should work with most things that you throw at it. Notably, sf objects should work out-of-the-box.

```{r}
library(geoarrow)

nc <- sf::read_sf(system.file("shape/nc.shp", package = "sf"))
write_geoarrow_parquet(nc, "nc.parquet")
arrow::read_parquet("nc.parquet")[c("NAME", "geometry")]
```

You can use any of the schemas to experiment by passing the `schema` argument:

```{r}
write_geoarrow_parquet(nc, "nc.parquet", schema = geoarrow_schema_wkt())
arrow::read_parquet("nc.parquet")[c("NAME", "geometry")]
```

```{r, include = FALSE}
unlink("nc.parquet")
```

## Type examples

First, extension types for the kind of encodings existing libraries support already:

```{r}
geom_linestring <- wk::wkt("LINESTRING (1 2, 2 3)")

carrow::from_carrow_array(
  geoarrow_create(geom_linestring, schema = geoarrow_schema_wkb()),
  arrow::Array
)

carrow::from_carrow_array(
  geoarrow_create(geom_linestring, schema = geoarrow_schema_wkt()),
  arrow::Array
)

carrow::from_carrow_array(
  geoarrow_create(geom_linestring, schema = geoarrow_schema_geojson()),
  arrow::Array
)
```

...but also Arrow-native forms that don't need to be parsed.

```{r}
geom_point <- wk::wkt("POINT (1 2)")
geom_linestring <- wk::wkt("LINESTRING (1 2, 2 3)")
geom_poly <- wk::wkt("POLYGON ((0 0, 1 1, 0 1, 0 0))")
geom_multipoint <- wk::wkt("MULTIPOINT (1 2)")
geom_multilinestring <- wk::wkt("MULTILINESTRING ((1 2, 2 3))")
geom_multipoly <- wk::wkt("MULTIPOLYGON (((0 0, 1 1, 0 1, 0 0)))")

carrow::from_carrow_array(geoarrow_create(geom_point), arrow::Array)
carrow::from_carrow_array(geoarrow_create(geom_linestring), arrow::Array)
carrow::from_carrow_array(geoarrow_create(geom_poly), arrow::Array)
carrow::from_carrow_array(geoarrow_create(geom_multipoint), arrow::Array)
carrow::from_carrow_array(geoarrow_create(geom_multilinestring), arrow::Array)
carrow::from_carrow_array(geoarrow_create(geom_multipoly), arrow::Array)
```

Collections currently fall back on WKB but could theoretically be supported using a union type:

```{r}
geom_collection <- wk::wkt("GEOMETRYCOLLECTION (POINT (0 1), LINESTRING (1 1, 2 2))")
carrow::from_carrow_array(geoarrow_create(geom_collection), arrow::Array)
```

The above examples all have a single feature/ring/linestring, so they fall back to using a fixed-width list. The ability to use a fixed-width list might be important if you have, say, 10 million rectangles that all have 5 points where there's no need to store a 64-bit offset to each coordinate. For cases where there's than `2 ^ 31` or more coordinates, the offsets will need to be 64-bit integers (i.e., large_list type). You can force either of these cases for any level of nesting by specifying a schema by hand:

```{r}
carrow::from_carrow_array(
  geoarrow_create(
    geom_poly,
    schema = geoarrow_schema_polygon(format = c("+L", "+l")),
    strict = TRUE
  ), 
  arrow::Array
)
```

There are a few options for point storage. The default is to store coordinates as a fixed-width list of doubles (float64) so that coordinates stay together in memory. This is probably fastest and mirrors the way that some other formats (e.g., WKB) store coordinates.

```{r}
(points <- wk::xy(1:3, 4:6))
array <- geoarrow_create(points)
as.numeric(array$array_data$children[[1]]$buffers[[2]])
```

Alternatively, you can store coordinates as a struct. This is much like storing x and y values in their own columns and might be useful if this is already how a user has these values in memory (e.g., the user read in a table where x and y values *were* their own columns). It also might be faster for operations like adding and dropping dimensions because the buffers stay separate for each dimension.

```{r}
array <- geoarrow_create(points, schema = geoarrow_schema_point_struct())
as.numeric(array$array_data$children[[1]]$buffers[[2]])
as.numeric(array$array_data$children[[2]]$buffers[[2]])
```

For both of these, it might be adequate to store values as float32 instead of float64. I didn't implement that here yet but in theory it shouldn't be a problem.

These are far from an exhaustive list of how coordinates can be stored. For example, S2 cell IDs (64-bit integers with ~1 cm resolution describing a location on the globe) are a fast and compact way to encode geographic coordinates. The H3 library has a similar scheme where each 64-bit integer describes a hexagon on the sphere. Some libraries use 32-bit integers scaled by 1e6 to represent longitude and latitude, and some provide an exact decimal type to skirt around floating point precision issues, particularly for internal calculations (e.g., decimal128 or decimal256).

It might not be worth supporting all the point storage formats in any particular implementation; however, the format is such that the coordinate array can be swapped out independent of the rest of the array structure.

## Why so many options?

The options are provided here so that implementations can experiment to see if more than one is worth supporting.

## Metadata

The schemas here use column-level extension types and extension metadata to encode dimension names, CRS information, and a flag to specify that edges should be considered geodesic rather than Cartesian.

```{r}
schema <- geoarrow_schema_linestring(
  geodesic = TRUE,
  point = geoarrow_schema_point(crs = "OGC:CRS84")
)
schema$metadata[["ARROW:extension:name"]]
geoarrow_metadata(schema)
geoarrow_metadata(schema$children[[1]])
```

I would argue that any string recognized by the latest PROJ release as a CRS is valid for the `crs` item (which lives with the point array). This includes full WKT2 output, which provides more detail at the expense of including redundant information that can get out of sync. I think "OGC:CRS84" or "EPSG:32620" are no less exact but are perhaps imprecise in a way I don't yet understand.
