---
title: "Getting started with geoarrow"
---

```{r, include = FALSE}
library(geoarrow)
library(arrow, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

One of the motivators to writing geoarrow was to leverage the features of the [arrow](https://arrow.apache.org/docs/r/) package and larger [Apache Arrow](https://arrow.apache.org/) ecosystem for bigger-than-memory data sets. In the arrow package, these are exposed as `Dataset` objects and can be created from one or more files using `arrow::open_dataset()`. There is [an excellent introduction to using Datasets with dplyr](https://arrow.apache.org/docs/r/articles/dataset.html) in the arrow package documentation that goes into detail, but the gist of it is that you can use `arrow::open_dataset()` to open a bigger-than-memory collection of files and query it using  the familiar `dplyr::filter()`, `dplyr::mutate()`, `dplyr::summarise()`, and `dplyr::arrange()`. 

## Opening a dataset

The geoarrow package provides a few functions simplify using `write_dataset()` and `open_dataset()` with datasets that contain geospatial data encoded as one or more columns. We'll use the arrow package, the dplyr package, and geoarrow. The geoarrow package includes a small test dataset of places in Denmark derived from [OpenStreetMap](https://openstreetmap.org) and processed by [GeoFabrik](https://download.geofabrik.de/europe/denmark.html).

```{r}
library(arrow)
library(dplyr)
library(geoarrow)

places_folder <- system.file("example_dataset/osm_places", package = "geoarrow")
list.files(places_folder, recursive = TRUE)
```

These files were written using `arrow::write_dataset()` and have hive-style partitioning (i.e., the folder name provides some information about the value of a certain field for files within that folder).

You can preview a dataset using `head()` and `geoarrow_collect_sf()`:

```{r}
places <- open_dataset(places_folder)
places %>% 
  head() %>% 
  geoarrow_collect_sf()
```

## Querying a data set

Just like a local data frame, you can use dplyr verbs like `filter()`, `mutate()` and `summarise()` to subset and manipulate the data before it is pulled into the R session. For example, to find all the places in Denmark with a population greater than 100,000 people, we can do this:

```{r}
places %>% 
  filter(population > 100000) %>% 
  select(name, population, fclass, geometry) %>% 
  geoarrow_collect_sf()
```

Geometry operators aren't yet supported within the Arrow compute engine, so any filtering or transformation on geometry columns must be done at the beginning (i.e., when selecting files to pass to `open_dataset()`) or at the end (i.e., after calling `geoarrow_collect_sf()`).

```{r}
capital <- places %>% 
  filter(name == "KÃ¸benhavn") %>% 
  geoarrow_collect_sf()

# cities within 200 km of the capital
places %>% 
  filter(fclass == "city") %>% 
  geoarrow_collect_sf() %>% 
  filter(
    s2::s2_dwithin(geometry, capital, 200000)
  )
```

## Using `geoarrow_collect()`

Until this point, we have used `geoarrow_collect_sf()`. This is probably what you want, since the fantastic [sf](https://r-spatial.github.io/sf/) package is a feature-complete GIS designed to work well with GIS data in data.frame form. If you want to customize how geometry columns are converted into R objects, you can use `geoarrow_collect()` with a `handler`. For example, if you want to convert geometry to a `wk::wkb()` directly without pivoting through sf, you can use `handler = wk::wkb_writer`.

```{r}
places %>% 
  head() %>% 
  geoarrow_collect(handler = wk::wkb_writer)
```

For large point data sets, it can be useful to represent geometry as a `wk::xy()`, which is a thin wrapper around `data.frame(x = c(), y = c())`. You can create these objects as geometry columns using `handler = wk::xy_writer`:

```{r}
(places_xy <- places %>% 
  select(name, geometry) %>% 
  geoarrow_collect(handler = wk::xy_writer))

xy <- as.data.frame(places_xy$geometry)
head(xy$x)
```
